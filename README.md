# nlp_project

Я буду работать с данными уже завершившегося [соревнования](https://github.com/dialogue-evaluation/RuSentNE-evaluation) по анализу тональности к именованным сущностям в новостных текстах. Посмотрим на описание, которое представлено в репозитории.

Анализ тональности текста &mdash; извлечение выраженной в тексте эмоциональной оценки к некоторой сущности &mdash; одно из наиболее активно развивающихся направлений в автоматической обработке текстов.

Анализ тональности новостных текстов &mdash; важное направление в области анализа мнений, поскольку обнаружение, отслеживание трендов тональности в новостном потоке важно для построения разного рода аналитических систем, отслеживания имиджа в СМИ конкретных людей или компаний.

Тональность по отношению к сущности в новостном тексте может происходить по крайней мере из трех разных источников:
* мнения автора текста;
* цитируемого мнения, при этом сам носитель мнения может быть упомянут или не упомянут в тексте;
* имплицитного мнения, которое следует из каких-либо упомянутых действий или реакций, например, X уволил Y. Такая информация часто присутствует даже при внешне нейтральном изложении событий.

#### Данные и метрика  
RuSentNE-2023 (train = 6 637, dev = 2 845; поля sentence, entity, entity_tag, label).
Macro-F1 по классам {-1; 1}, neutral игнорируется.

#### Лучший эксперимент RuRoberta-large + теги
macro-F1 = 0.74, accuracy = 0.832, eval_loss = 0.51 
Тег-сущность дает модели явные указания, вектор `[TAG]` концентрирует градиенты, что улучшает различимость тональности.  
Большая Roberta имеет большую вместимость, лучше моделирует длинные зависимые связи.  

#### Дополнительный эксперимент — half-masked ensemble  
По [Kabaev et al., 2023] идея:  
1. Прогнать предложение с размеченной сущностью.  
2. Второй прогон — заменить сущность на `[MASK]`.  
3. Усреднить логиты.  

Это снижает переобучение: модель смотрит и на окружение, и на сам токен.

#### Литература

Soares et al., 2019 — entity-aware pooling.
Micikevicius et al., 2017 — mixed precision AMP.
Chen et al., 2016 — gradient checkpointing.
Zavalishina et al., 2023 (arXiv:2305.17679) — спец-токены и mean-pool для задачи соревнования; мы использовали их приёмы и гиперпараметры.

#### Вывод
Простые приемы (использование токенов, большая модель) дают +20 п. F1 по сравнению с бейзлайном.
