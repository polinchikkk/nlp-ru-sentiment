# nlp-ru-sentiment

Работа ведётся на основе данных уже завершившегося соревнования [RuSentNE-2023](https://github.com/dialogue-evaluation/RuSentNE-evaluation) по анализу тональности в отношении именованных сущностей в новостных текстах. Цель — определить, выражена ли в тексте позитивная или негативная оценка заданной сущности, игнорируя нейтральные случаи.

## Мотивация

Анализ тональности текста — извлечение эмоциональной оценки, адресованной конкретной сущности — одно из ключевых направлений в автоматическом понимании мнений. В новостных текстах это особенно важно для:

- мониторинга имиджа людей или организаций;  
- отслеживания трендов в медиапространстве;  
- построения аналитических систем, реагирующих на изменение общественного восприятия.

Тональность по отношению к сущности может быть выражена через:

- субъективное мнение автора;  
- цитируемое мнение (возможно, без явного явного источника);  
- имплицитное значение, вытекающее из описания действий или событий (например, «X уволил Y»).

## Данные и метрика (RuSentNE)

### Разбиение
| Набор | Примеры | Примечание |
|-------|---------|------------|
| train | 6 637   | Содержит метки `-1` / `1` |
| dev   | 2 845   | Нейтральные примеры игнорируются при оценке |

### Поля
| Поле | Описание |
|------|----------|
| `sentence` | Предложение из новостного текста |
| `entity` | Именованная сущность, к которой относится тональность |
| `entity_tag` | Специальное обозначение сущности в тексте (например, обёртывание в `[TAG]`) |
| `label` | Целевая метка: `1` или `-1` (нейтральные примеры исключаются из метрики) |

### Целевая метрика
| Метрика | Описание |
|---------|----------|
| Макро-F1 по классам `{-1, 1}` | Среднее F1 по негативу и позитиву; нейтральные исключаются |
| Accuracy | Доля верных предсказаний (для дополнительного анализа) |

## Подходы и лучшие практики

### Основной подход: RuRoberta-large + entity tags  
Лучший эксперимент показал:  
- **макро-F1 = 0.74**,  
- **accuracy = 0.832**,  
- **eval_loss = 0.51**

**Идея:**  
Явное указание сущности через специальные токены/теги (например, обёртывание сущности в `[TAG]`) помогает модели сфокусировать градиенты на нужном фрагменте и точнее различать тональность именно этой сущности. Крупная предобученная модель RuRoberta-large лучше моделирует длинные зависимые связи и обладает достаточной вместимостью для захвата контекстных нюансов.

### Дополнительный эксперимент: half-masked ensemble  
По идее из Kabaev et al., 2023:  
1. Прогон предложения с размеченной сущностью.  
2. Прогон того же предложения, но с заменённой сущностью на `[MASK]`.  
3. Усреднение логитов обоих прогонов.

**Преимущества:**  
Снижает переобучение, поскольку модель одновременно учитывает контекст вокруг сущности и абстрагированное представление без явного указания сущности, делая предсказания более устойчивыми.

## Реализация (кратко)

- Используются специальные токены/теги вокруг сущности для её индикации.  
- Инициализация на предобученной модели RuRoberta-large.  
- Применяется смешанная точность (AMP) для ускорения и экономии памяти.  
- Используется gradient checkpointing для контроля потребления памяти при обучении большой модели.  
- Ансамблирование через half-masked стратегию повышает стабильность предсказаний.

## Результаты

| Модель / приём | Макро-F1 | Accuracy | Примечания |
|----------------|----------|----------|------------|
| RuRoberta-large + entity tags | 0.74 | 0.832 | Спец-теги усиливают фокус на сущности |
| half-masked ensemble (Kabaev et al., 2023) | комбинированно | — | Усреднение логитов оригинального и маскированного представлений снижает переобучение |

## Литература

- Soares et al., 2019 — entity-aware pooling (контекстно-зависимое объединение сущностей).  
- Micikevicius et al., 2017 — обучение со смешанной точностью (AMP).  
- Chen et al., 2016 — gradient checkpointing для экономии памяти при обучении глубоких моделей.  
- Завалишина и др., 2023 (arXiv:2305.17679) — специальные токены и mean-pooling для задач анализа тональности по сущностям; использованы идеи и гиперпараметры.  
- Kabaev et al., 2023 — half-masked ensemble (усреднение логитов оригинального и маскированного представлений).

## Дальнейшие шаги

- Эксперименты с альтернативными способами индикации сущности (позиционные представления, span-aware embeddings).  
- Расширение ансамблей (разные маскировки, разные модели).  
- Калибровка предсказаний и анализ ошибок по типам сущностей и контекстов.
